{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class OUNoise(object):\n",
    "    def __init__(self, action_space, mu=0.0, theta=0.15, max_sigma=0.7, min_sigma=0.4, decay_period=600_000):\n",
    "        self.mu = mu\n",
    "        self.theta = theta\n",
    "        self.sigma = max_sigma\n",
    "        self.max_sigma = max_sigma\n",
    "        self.min_sigma = min_sigma\n",
    "        self.decay_period = decay_period\n",
    "        self.action_dim = action_space\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = np.ones(self.action_dim) * self.mu\n",
    "\n",
    "    def evolve_state(self):\n",
    "        x = self.state\n",
    "        dx = self.theta * (self.mu - x) + self.sigma * np.random.randn(self.action_dim)\n",
    "        self.state = x + dx\n",
    "        return self.state\n",
    "\n",
    "    def get_noise(self, t=0):\n",
    "        ou_state = self.evolve_state()\n",
    "        decaying = float(float(t) / self.decay_period)\n",
    "        self.sigma = max(self.sigma - (self.max_sigma - self.min_sigma) * min(1.0, decaying), self.min_sigma)\n",
    "        print('sigma:', self.sigma, 'state:', ou_state)\n",
    "        return ou_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = OUNoise(action_space=2, max_sigma=0.9, min_sigma=0.1, decay_period=500_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma: 0.8904 state: [0.23640066 1.72709601]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.23640066, 1.72709601])"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise.get_noise(t=60_00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "from env_utils import GoalManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mObstacle name: wall_outler, base pose: (0.0, 0.0, 0.0)\u001b[0m\n",
      "Coordinates: [[[11.5, -8.425], [11.5, -11.575], [-11.5, -11.575], [-11.5, -8.425]], [[21.5, 1.575], [21.5, -1.575], [-1.5, -1.575], [-1.5, 1.575]], [[11.5, 11.575], [11.5, 8.425], [-11.5, 8.425], [-11.5, 11.575]], [[1.5, 1.575], [1.5, -1.575], [-21.5, -1.575], [-21.5, 1.575]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "GM = GoalManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([574.9388, 754.5155, 960.6138, 782.7532, 402.9149])\n",
      "tensor([0.3567, 0.4681, 0.5960, 0.4857, 0.2500])\n",
      "tensor([0.3567, 0.4681, 0.5960, 0.4857, 0.2500])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "v = torch.rand(5) * 1000\n",
    "v_1 = v.clone()\n",
    "v.requires_grad_(True)\n",
    "v_1.requires_grad_(True)\n",
    "\n",
    "loss = 1/2 * torch.sum(v_1 * v_1 + v * v)\n",
    "# Here grads of loss w.r.t v and v_1 should be v and v_1 respectively\n",
    "loss.backward()\n",
    "\n",
    "# Clip grads of v_1\n",
    "torch.nn.utils.clip_grad_norm_(v_1, max_norm=1.0, norm_type=2)\n",
    "\n",
    "print(v.grad)\n",
    "print(v_1.grad)\n",
    "print(v.grad / torch.norm(v.grad, p=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([574.9388, 754.5155, 960.6138, 782.7532, 402.9149])\n",
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "v_2 = v_1.clone()\n",
    "\n",
    "v_3 = torch.tanh(v_2)\n",
    "\n",
    "v_2.requires_grad_(True)\n",
    "v_3.requires_grad_(True)\n",
    "\n",
    "loss2 = 1/2 * torch.sum(v_2 * v_2 + v_3 * v_3)\n",
    "\n",
    "# Retain grad for v_2 and v_3\n",
    "v_2.retain_grad()\n",
    "v_3.retain_grad()\n",
    "\n",
    "loss2.backward()\n",
    "\n",
    "print(v_2.grad)\n",
    "print(v_3.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Actor(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "    name,           # Name of the network\n",
    "    state_size,     # Number of input neurons\n",
    "    action_size,    # Number of output neurons\n",
    "    hidden_size,     # Number of neurons in hidden layers\n",
    "    ):\n",
    "        super(Actor, self).__init__()\n",
    "        self.name = name\n",
    "        self.iteration = 0\n",
    "\n",
    "        # Layer Definition\n",
    "        self.fa1 = nn.Linear(state_size, hidden_size)\n",
    "        self.fa2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fa3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fa4 = nn.Linear(hidden_size, action_size)\n",
    "\n",
    "        for name, param in self.named_parameters():\n",
    "            if param.is_leaf:\n",
    "                print(f\"Parameter {name} is a leaf tensor.\")\n",
    "\n",
    "        # Initialize weights\n",
    "        # Using Kaiming initialization\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def init_weights(self, m: torch.nn.Module):\n",
    "        # Initialize the weights of the network\n",
    "        if isinstance(m, torch.nn.Linear):\n",
    "            # Kaiming He initialization\n",
    "            torch.nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "            m.bias.data.fill_(0.0)\n",
    "\n",
    "    def forward(self, states, visualize=False):\n",
    "        # Forward pass\n",
    "        x1 = torch.relu(self.fa1(states))\n",
    "        x2 = torch.relu(self.fa2(x1))\n",
    "        x3 = torch.relu(self.fa3(x2))\n",
    "        action = torch.tanh(self.fa4(x3))\n",
    "\n",
    "        return action\n",
    "    \n",
    "class Critic(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "    name,           # Name of the network \n",
    "    state_size,     # Number of input neurons\n",
    "    action_size,    # Number of output neurons\n",
    "    hidden_size,     # Number of neurons in hidden layers\n",
    "    ):\n",
    "        super(Critic, self).__init__()\n",
    "        self.name = name\n",
    "        self.iteration = 0\n",
    "\n",
    "        # Q1 Architecture\n",
    "        self.l01 = nn.Linear(state_size + action_size, hidden_size)\n",
    "        self.l02 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.l03 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.l04 = nn.Linear(hidden_size, 1)\n",
    "\n",
    "        # Q2 Architecture\n",
    "        self.l11 = nn.Linear(state_size + action_size, hidden_size)\n",
    "        self.l12 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.l13 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.l14 = nn.Linear(hidden_size, 1)\n",
    "\n",
    "        for name, param in self.named_parameters():\n",
    "            if param.is_leaf:\n",
    "                print(f\"Parameter {name} is a leaf tensor.\")\n",
    "\n",
    "        # Initialize weights\n",
    "        # Using Kaiming initialization\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def init_weights(self, m: torch.nn.Module):\n",
    "        # Initialize the weights of the network\n",
    "        if isinstance(m, torch.nn.Linear):\n",
    "            # Kaiming He initialization\n",
    "            torch.nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "            m.bias.data.fill_(0.0)\n",
    "\n",
    "    def forward(self, states, actions, visualize=False) -> torch.Tensor:\n",
    "        \n",
    "        # Concatenate the states and actions\n",
    "        sa = torch.cat((states, actions), dim=1)\n",
    "\n",
    "        # Q1 forward pass\n",
    "        x01 = torch.relu(self.l01(sa))\n",
    "        x02 = torch.relu(self.l02(x01))\n",
    "        x03 = torch.relu(self.l03(x02))\n",
    "        q1 = self.l04(x03)\n",
    "\n",
    "        # Q2 forward pass\n",
    "        x11 = torch.relu(self.l11(sa))\n",
    "        x12 = torch.relu(self.l12(x11))\n",
    "        x13 = torch.relu(self.l13(x12))\n",
    "        q2 = self.l14(x13)\n",
    "\n",
    "        return q1, q2\n",
    "\n",
    "\n",
    "    def Q1_forward(self, states, actions) -> torch.Tensor:\n",
    "        \n",
    "        # Concatenate the states and actions\n",
    "        sa = torch.cat((states, actions), dim=1)\n",
    "\n",
    "        # Q1 forward pass\n",
    "        x01 = torch.relu(self.l01(sa))\n",
    "        x02 = torch.relu(self.l02(x01))\n",
    "        x03 = torch.relu(self.l03(x02))\n",
    "        q1 = self.l04(x03)\n",
    "\n",
    "        return q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter l01.weight is a leaf tensor.\n",
      "Parameter l01.bias is a leaf tensor.\n",
      "Parameter l02.weight is a leaf tensor.\n",
      "Parameter l02.bias is a leaf tensor.\n",
      "Parameter l03.weight is a leaf tensor.\n",
      "Parameter l03.bias is a leaf tensor.\n",
      "Parameter l04.weight is a leaf tensor.\n",
      "Parameter l04.bias is a leaf tensor.\n",
      "Parameter l11.weight is a leaf tensor.\n",
      "Parameter l11.bias is a leaf tensor.\n",
      "Parameter l12.weight is a leaf tensor.\n",
      "Parameter l12.bias is a leaf tensor.\n",
      "Parameter l13.weight is a leaf tensor.\n",
      "Parameter l13.bias is a leaf tensor.\n",
      "Parameter l14.weight is a leaf tensor.\n",
      "Parameter l14.bias is a leaf tensor.\n"
     ]
    }
   ],
   "source": [
    "state_size = 10\n",
    "action_size = 2\n",
    "\n",
    "actor = Actor('actor', state_size, action_size, 256).to(device)\n",
    "critic = Critic('critic', state_size, action_size, 256).to(device)\n",
    "\n",
    "actor_optimizer = torch.optim.AdamW(actor.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_actor: 0.09932661056518555\n",
      "tensor([[0.0049, 0.0037, 0.0051,  ..., 0.0029, 0.0026, 0.0048],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0106, 0.0081, 0.0111,  ..., 0.0063, 0.0056, 0.0105],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.0056,  0.0000,  0.0123,  0.0072,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0004,  0.0000,  0.0000, -0.0074,  0.0000,  0.0039,  0.0000,\n",
      "        -0.0092, -0.0121,  0.0000,  0.0000,  0.0000,  0.0000, -0.0025,  0.0000,\n",
      "        -0.0119,  0.0054,  0.0045, -0.0068,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "        -0.0133,  0.0000,  0.0050,  0.0000, -0.0076,  0.0000,  0.0040,  0.0000,\n",
      "         0.0000,  0.0072,  0.0000,  0.0000,  0.0031,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0069,  0.0089,  0.0000,\n",
      "         0.0006,  0.0005,  0.0024,  0.0000, -0.0003,  0.0000,  0.0051, -0.0050,\n",
      "        -0.0019,  0.0208,  0.0106,  0.0129,  0.0029,  0.0000, -0.0051,  0.0000,\n",
      "         0.0000, -0.0029, -0.0033, -0.0010,  0.0000,  0.0000, -0.0088,  0.0000,\n",
      "         0.0000, -0.0070, -0.0149,  0.0073,  0.0022,  0.0000,  0.0000,  0.0083,\n",
      "         0.0064,  0.0000, -0.0026,  0.0000,  0.0000,  0.0000, -0.0041,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0078,  0.0000,  0.0171,  0.0019,  0.0093,\n",
      "         0.0073,  0.0000,  0.0129,  0.0000, -0.0139, -0.0060, -0.0023,  0.0000,\n",
      "        -0.0011,  0.0000,  0.0098,  0.0000,  0.0000,  0.0000,  0.0000,  0.0053,\n",
      "        -0.0112,  0.0000,  0.0000,  0.0000,  0.0007,  0.0000,  0.0033,  0.0021,\n",
      "         0.0079, -0.0037,  0.0000,  0.0024,  0.0000,  0.0002, -0.0031,  0.0000,\n",
      "         0.0000,  0.0000, -0.0110, -0.0053,  0.0000,  0.0000,  0.0000, -0.0025,\n",
      "         0.0029, -0.0071, -0.0096, -0.0112,  0.0000,  0.0000,  0.0093, -0.0096,\n",
      "        -0.0050,  0.0079,  0.0000,  0.0000,  0.0000,  0.0000,  0.0025,  0.0010,\n",
      "        -0.0045, -0.0058,  0.0020,  0.0000,  0.0000, -0.0018,  0.0000,  0.0000,\n",
      "         0.0000, -0.0041,  0.0000,  0.0000,  0.0011, -0.0034,  0.0000, -0.0008,\n",
      "         0.0000,  0.0000,  0.0000,  0.0089,  0.0000,  0.0000,  0.0000, -0.0025,\n",
      "         0.0068,  0.0000,  0.0000, -0.0059,  0.0092, -0.0107,  0.0158,  0.0120,\n",
      "         0.0057,  0.0000,  0.0000,  0.0000, -0.0010,  0.0000,  0.0008,  0.0000,\n",
      "         0.0000, -0.0005,  0.0016,  0.0000,  0.0000, -0.0045,  0.0000,  0.0026,\n",
      "        -0.0042,  0.0037,  0.0000,  0.0000,  0.0069,  0.0065,  0.0046,  0.0059,\n",
      "        -0.0047, -0.0044,  0.0000,  0.0000, -0.0100,  0.0000, -0.0070, -0.0051,\n",
      "         0.0000,  0.0000, -0.0079,  0.0000, -0.0093,  0.0021,  0.0069, -0.0036,\n",
      "         0.0006,  0.0187,  0.0000,  0.0000,  0.0000, -0.0107,  0.0000,  0.0000,\n",
      "         0.0056,  0.0026,  0.0000,  0.0000,  0.0000, -0.0024,  0.0056, -0.0065,\n",
      "         0.0022,  0.0000,  0.0000,  0.0000, -0.0021,  0.0000,  0.0000,  0.0000],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0050,  0.0000,  0.0028,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0043, -0.0000, -0.0024,  ..., -0.0000, -0.0000, -0.0000],\n",
      "        ...,\n",
      "        [-0.0128, -0.0000, -0.0071,  ..., -0.0000, -0.0000, -0.0000],\n",
      "        [ 0.0039,  0.0000,  0.0022,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0204, -0.0000, -0.0113,  ..., -0.0000, -0.0000, -0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.0000,  0.0034, -0.0029,  0.0000,  0.0000, -0.0114,  0.0000,  0.0000,\n",
      "        -0.0011, -0.0051,  0.0000,  0.0000,  0.0000,  0.0008,  0.0192,  0.0125,\n",
      "        -0.0042,  0.0000, -0.0065,  0.0000,  0.0000,  0.0000, -0.0085,  0.0000,\n",
      "        -0.0021,  0.0042, -0.0020,  0.0000, -0.0040,  0.0000,  0.0028, -0.0040,\n",
      "        -0.0067, -0.0109,  0.0000, -0.0113, -0.0063,  0.0080,  0.0000,  0.0000,\n",
      "         0.0088, -0.0068,  0.0068,  0.0000,  0.0000,  0.0000,  0.0045,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000, -0.0108,  0.0038,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, -0.0004,  0.0000, -0.0164,  0.0000,  0.0000,\n",
      "        -0.0079,  0.0000,  0.0012,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0049,  0.0005, -0.0003,  0.0073,  0.0000,  0.0101,\n",
      "         0.0094, -0.0084,  0.0000, -0.0027, -0.0123, -0.0040,  0.0000,  0.0028,\n",
      "         0.0026,  0.0000,  0.0043,  0.0000,  0.0000,  0.0000,  0.0005,  0.0000,\n",
      "         0.0022,  0.0013,  0.0014,  0.0077, -0.0011,  0.0062,  0.0000,  0.0000,\n",
      "        -0.0032,  0.0000,  0.0106,  0.0000,  0.0000, -0.0032,  0.0022,  0.0000,\n",
      "         0.0026, -0.0006,  0.0086,  0.0000, -0.0059,  0.0070,  0.0000,  0.0050,\n",
      "         0.0081,  0.0000,  0.0069,  0.0000,  0.0016,  0.0000, -0.0061,  0.0011,\n",
      "         0.0041,  0.0000,  0.0000,  0.0000,  0.0020,  0.0037,  0.0000,  0.0000,\n",
      "         0.0000, -0.0085,  0.0014,  0.0057,  0.0000,  0.0000,  0.0000, -0.0023,\n",
      "        -0.0102,  0.0000,  0.0000,  0.0000, -0.0004,  0.0000,  0.0033,  0.0000,\n",
      "         0.0001,  0.0087,  0.0000,  0.0000,  0.0082,  0.0000,  0.0000,  0.0000,\n",
      "        -0.0002,  0.0041, -0.0001,  0.0020,  0.0000, -0.0064,  0.0000,  0.0000,\n",
      "         0.0000,  0.0077,  0.0000,  0.0027, -0.0017,  0.0005, -0.0022, -0.0001,\n",
      "         0.0044, -0.0085,  0.0000,  0.0004,  0.0000,  0.0013,  0.0000,  0.0000,\n",
      "        -0.0031,  0.0083,  0.0000,  0.0067,  0.0098,  0.0016,  0.0080,  0.0000,\n",
      "         0.0000, -0.0086,  0.0000,  0.0069,  0.0000,  0.0048,  0.0000, -0.0008,\n",
      "        -0.0046,  0.0000,  0.0041,  0.0061,  0.0000,  0.0000,  0.0000, -0.0038,\n",
      "         0.0000,  0.0000, -0.0004,  0.0000,  0.0000,  0.0000,  0.0000, -0.0004,\n",
      "         0.0000, -0.0011,  0.0000,  0.0000,  0.0045,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0039,  0.0065,  0.0029,  0.0000, -0.0017,  0.0000,\n",
      "        -0.0100,  0.0017,  0.0000,  0.0000,  0.0000, -0.0024,  0.0000,  0.0000,\n",
      "        -0.0083,  0.0000,  0.0000, -0.0035,  0.0121, -0.0002,  0.0059,  0.0000,\n",
      "         0.0000,  0.0064, -0.0090,  0.0092, -0.0149, -0.0087,  0.0026, -0.0138],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.0000, -0.0008, -0.0006,  ..., -0.0002, -0.0014, -0.0016],\n",
      "        [ 0.0000,  0.0047,  0.0036,  ...,  0.0010,  0.0081,  0.0090],\n",
      "        [ 0.0000,  0.0052,  0.0040,  ...,  0.0011,  0.0089,  0.0100],\n",
      "        ...,\n",
      "        [-0.0000, -0.0046, -0.0035,  ..., -0.0010, -0.0079, -0.0088],\n",
      "        [ 0.0000,  0.0054,  0.0041,  ...,  0.0011,  0.0092,  0.0103],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([-0.0015,  0.0086,  0.0095, -0.0046,  0.0155,  0.0023,  0.0000,  0.0060,\n",
      "        -0.0068, -0.0033, -0.0127, -0.0095,  0.0000, -0.0142,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0024,  0.0028,  0.0000,\n",
      "         0.0000,  0.0046,  0.0000, -0.0077, -0.0035,  0.0000,  0.0000, -0.0061,\n",
      "         0.0000,  0.0000,  0.0008,  0.0004,  0.0000,  0.0006,  0.0000, -0.0009,\n",
      "         0.0000,  0.0057,  0.0103,  0.0016,  0.0000,  0.0000,  0.0110, -0.0008,\n",
      "         0.0000, -0.0092,  0.0000,  0.0000,  0.0000,  0.0016,  0.0000, -0.0022,\n",
      "         0.0115,  0.0000, -0.0066, -0.0084, -0.0033,  0.0074,  0.0000,  0.0000,\n",
      "         0.0000, -0.0090, -0.0045,  0.0055,  0.0000,  0.0000, -0.0014,  0.0072,\n",
      "         0.0000,  0.0000,  0.0000, -0.0111,  0.0035, -0.0085,  0.0009,  0.0000,\n",
      "         0.0000,  0.0067,  0.0121,  0.0016,  0.0000,  0.0000,  0.0026,  0.0081,\n",
      "        -0.0004,  0.0000,  0.0000, -0.0050,  0.0003,  0.0000,  0.0000,  0.0000,\n",
      "         0.0036,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0010,\n",
      "         0.0000, -0.0035, -0.0078, -0.0108,  0.0000,  0.0086,  0.0000, -0.0067,\n",
      "         0.0000,  0.0000,  0.0000,  0.0088,  0.0000,  0.0071,  0.0000, -0.0013,\n",
      "         0.0000,  0.0000,  0.0033, -0.0014,  0.0000, -0.0023,  0.0018,  0.0000,\n",
      "        -0.0056,  0.0000,  0.0070,  0.0000, -0.0036, -0.0109,  0.0006,  0.0014,\n",
      "         0.0000, -0.0002,  0.0000, -0.0059,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0065, -0.0008,  0.0124,  0.0000,  0.0062,  0.0051,  0.0112,\n",
      "         0.0000,  0.0000,  0.0000, -0.0040,  0.0000,  0.0000,  0.0081,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0090, -0.0065,  0.0044, -0.0030,\n",
      "         0.0117,  0.0000,  0.0063, -0.0044,  0.0105, -0.0069, -0.0063,  0.0000,\n",
      "        -0.0014, -0.0104, -0.0018, -0.0043,  0.0000,  0.0000,  0.0000,  0.0008,\n",
      "         0.0000,  0.0000,  0.0000,  0.0064,  0.0124,  0.0039,  0.0000,  0.0000,\n",
      "         0.0000, -0.0115,  0.0000, -0.0065, -0.0048,  0.0008,  0.0000, -0.0030,\n",
      "        -0.0081,  0.0000,  0.0055,  0.0000,  0.0000, -0.0080,  0.0000, -0.0086,\n",
      "        -0.0047,  0.0024,  0.0000,  0.0000, -0.0056,  0.0005,  0.0042,  0.0067,\n",
      "         0.0030,  0.0071,  0.0000, -0.0012,  0.0000,  0.0015,  0.0000,  0.0069,\n",
      "         0.0000,  0.0000,  0.0144,  0.0027, -0.0082,  0.0096,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0004,  0.0000,  0.0054,  0.0000, -0.0027,\n",
      "        -0.0032,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0062,  0.0000,\n",
      "         0.0000, -0.0067,  0.0000,  0.0000,  0.0000, -0.0084,  0.0098,  0.0000],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.0198,  0.0078,  0.0083,  0.0057,  0.0020,  0.0178,  0.0000,  0.0372,\n",
      "          0.0358,  0.0019,  0.0181,  0.0008,  0.0000,  0.0071,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0023,  0.0305,  0.0000,\n",
      "          0.0000,  0.0206,  0.0000,  0.0242,  0.0105,  0.0000,  0.0000,  0.0183,\n",
      "          0.0000,  0.0000,  0.0095,  0.0168,  0.0000,  0.0173,  0.0000,  0.0007,\n",
      "          0.0000,  0.0420,  0.0142,  0.0009,  0.0000,  0.0000,  0.0213,  0.0252,\n",
      "          0.0000,  0.0084,  0.0000,  0.0000,  0.0000,  0.0192,  0.0000,  0.0066,\n",
      "          0.0002,  0.0000,  0.0169,  0.0276,  0.0169,  0.0294,  0.0000,  0.0000,\n",
      "          0.0000,  0.0234,  0.0049,  0.0112,  0.0000,  0.0000,  0.0046,  0.0152,\n",
      "          0.0000,  0.0000,  0.0000,  0.0019,  0.0326,  0.0095,  0.0044,  0.0000,\n",
      "          0.0000,  0.0465,  0.0203,  0.0075,  0.0000,  0.0000,  0.0189,  0.0147,\n",
      "          0.0443,  0.0000,  0.0000,  0.0292,  0.0119,  0.0000,  0.0000,  0.0000,\n",
      "          0.0265,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0191,\n",
      "          0.0000,  0.0248,  0.0058,  0.0253,  0.0000,  0.0030,  0.0000,  0.0115,\n",
      "          0.0000,  0.0000,  0.0000,  0.0301,  0.0000,  0.0275,  0.0000,  0.0106,\n",
      "          0.0000,  0.0000,  0.0043,  0.0089,  0.0000,  0.0004,  0.0028,  0.0000,\n",
      "          0.0217,  0.0000,  0.0393,  0.0000,  0.0435,  0.0088,  0.0108,  0.0074,\n",
      "          0.0000,  0.0539,  0.0000,  0.0068,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0283,  0.0477,  0.0129,  0.0000,  0.0106,  0.0117,  0.0028,\n",
      "          0.0000,  0.0000,  0.0000,  0.0168,  0.0000,  0.0000,  0.0181,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0301,  0.0211,  0.0106,  0.0329,\n",
      "          0.0005,  0.0000,  0.0073,  0.0067,  0.0331,  0.0076,  0.0071,  0.0000,\n",
      "          0.0060,  0.0152,  0.0061,  0.0453,  0.0000,  0.0000,  0.0000,  0.0012,\n",
      "          0.0000,  0.0000,  0.0000,  0.0363,  0.0167,  0.0093,  0.0000,  0.0000,\n",
      "          0.0000,  0.0039,  0.0000,  0.0356,  0.0029,  0.0068,  0.0000,  0.0210,\n",
      "          0.0151,  0.0000,  0.0226,  0.0000,  0.0000,  0.0047,  0.0000,  0.0043,\n",
      "          0.0070,  0.0250,  0.0000,  0.0000,  0.0138,  0.0057,  0.0319,  0.0130,\n",
      "          0.0141,  0.0048,  0.0000,  0.0249,  0.0000,  0.0061,  0.0000,  0.0014,\n",
      "          0.0000,  0.0000,  0.0160,  0.0286,  0.0313,  0.0387,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0070,  0.0000,  0.0075,  0.0000,  0.0205,\n",
      "          0.0152,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0095,  0.0000,\n",
      "          0.0000,  0.0067,  0.0000,  0.0000,  0.0000,  0.0118,  0.0123,  0.0000],\n",
      "        [-0.0449, -0.0176, -0.0189, -0.0130, -0.0045, -0.0403, -0.0000, -0.0843,\n",
      "         -0.0813, -0.0043, -0.0410, -0.0017, -0.0000, -0.0160, -0.0000, -0.0000,\n",
      "         -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0052, -0.0692, -0.0000,\n",
      "         -0.0000, -0.0468, -0.0000, -0.0549, -0.0239, -0.0000, -0.0000, -0.0415,\n",
      "         -0.0000, -0.0000, -0.0215, -0.0381, -0.0000, -0.0392, -0.0000, -0.0015,\n",
      "         -0.0000, -0.0952, -0.0322, -0.0021, -0.0000, -0.0000, -0.0484, -0.0571,\n",
      "         -0.0000, -0.0192, -0.0000, -0.0000, -0.0000, -0.0436, -0.0000, -0.0151,\n",
      "         -0.0006, -0.0000, -0.0384, -0.0626, -0.0382, -0.0667, -0.0000, -0.0000,\n",
      "         -0.0000, -0.0531, -0.0112, -0.0253, -0.0000, -0.0000, -0.0104, -0.0344,\n",
      "         -0.0000, -0.0000, -0.0000, -0.0044, -0.0740, -0.0216, -0.0101, -0.0000,\n",
      "         -0.0000, -0.1054, -0.0460, -0.0171, -0.0000, -0.0000, -0.0429, -0.0333,\n",
      "         -0.1004, -0.0000, -0.0000, -0.0663, -0.0270, -0.0000, -0.0000, -0.0000,\n",
      "         -0.0601, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0433,\n",
      "         -0.0000, -0.0562, -0.0133, -0.0574, -0.0000, -0.0069, -0.0000, -0.0260,\n",
      "         -0.0000, -0.0000, -0.0000, -0.0682, -0.0000, -0.0623, -0.0000, -0.0240,\n",
      "         -0.0000, -0.0000, -0.0097, -0.0201, -0.0000, -0.0008, -0.0063, -0.0000,\n",
      "         -0.0493, -0.0000, -0.0891, -0.0000, -0.0988, -0.0199, -0.0246, -0.0168,\n",
      "         -0.0000, -0.1222, -0.0000, -0.0155, -0.0000, -0.0000, -0.0000, -0.0000,\n",
      "         -0.0000, -0.0642, -0.1082, -0.0293, -0.0000, -0.0240, -0.0265, -0.0063,\n",
      "         -0.0000, -0.0000, -0.0000, -0.0382, -0.0000, -0.0000, -0.0411, -0.0000,\n",
      "         -0.0000, -0.0000, -0.0000, -0.0000, -0.0683, -0.0478, -0.0241, -0.0747,\n",
      "         -0.0010, -0.0000, -0.0165, -0.0151, -0.0751, -0.0173, -0.0161, -0.0000,\n",
      "         -0.0136, -0.0344, -0.0138, -0.1029, -0.0000, -0.0000, -0.0000, -0.0028,\n",
      "         -0.0000, -0.0000, -0.0000, -0.0823, -0.0378, -0.0211, -0.0000, -0.0000,\n",
      "         -0.0000, -0.0087, -0.0000, -0.0808, -0.0067, -0.0155, -0.0000, -0.0476,\n",
      "         -0.0343, -0.0000, -0.0514, -0.0000, -0.0000, -0.0106, -0.0000, -0.0096,\n",
      "         -0.0159, -0.0566, -0.0000, -0.0000, -0.0313, -0.0129, -0.0723, -0.0295,\n",
      "         -0.0320, -0.0109, -0.0000, -0.0564, -0.0000, -0.0138, -0.0000, -0.0033,\n",
      "         -0.0000, -0.0000, -0.0364, -0.0648, -0.0710, -0.0878, -0.0000, -0.0000,\n",
      "         -0.0000, -0.0000, -0.0000, -0.0159, -0.0000, -0.0170, -0.0000, -0.0464,\n",
      "         -0.0344, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0215, -0.0000,\n",
      "         -0.0000, -0.0152, -0.0000, -0.0000, -0.0000, -0.0267, -0.0279, -0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.0287, -0.0651], device='cuda:0')\n",
      "Grad norm of actor: 1.1005029678344727\n"
     ]
    }
   ],
   "source": [
    "random_state = torch.rand(1, state_size).to(device)\n",
    "\n",
    "action = actor(random_state)\n",
    "\n",
    "loss_actor = -critic.Q1_forward(random_state, action).mean()\n",
    "\n",
    "print(f'loss_actor: {loss_actor}')\n",
    "\n",
    "actor_optimizer.zero_grad()\n",
    "loss_actor.backward()\n",
    "for p in actor.parameters():\n",
    "    print(p.grad)\n",
    "\n",
    "print(f'Grad norm of actor: {torch.norm(torch.cat([p.grad.flatten() for p in actor.parameters()]))}')\n",
    "\n",
    "actor_optimizer.step()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
